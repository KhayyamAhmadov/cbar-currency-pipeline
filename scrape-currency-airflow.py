from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup
import psycopg2
import time

# =========================
# PostgreSQL baÄŸlantÄ±sÄ±
# =========================
def get_conn():
    return psycopg2.connect(
        dbname='currency',
        user='postgres',
        password='1234',
        host='host.docker.internal',
        port='5432'
    )

# =========================
# Valyuta mÉ™lumatlarÄ±nÄ± Ã§É™kÉ™n funksiya
# =========================
def scrape_currency(date_to_scrape):
    conn = get_conn()
    cur = conn.cursor()

    # Cbar.az linki Ã¼Ã§Ã¼n +1 gÃ¼n
    query_date = date_to_scrape + timedelta(days=1)
    date_str = query_date.strftime("%d/%m/%Y")
    url = f"https://www.cbar.az/currency/rates?date={date_str}"
    print(f"ğŸ”¹ SorÄŸu gÃ¶ndÉ™rilir: {date_str} (É™sl tarix: {date_to_scrape.date()})")

    r = requests.get(url)
    if r.status_code != 200:
        print(f"âš ï¸ {query_date.date()} Ã¼Ã§Ã¼n sÉ™hv kod: {r.status_code}")
        return

    soup = BeautifulSoup(r.text, "html.parser")
    rows = soup.select("div.table_row")

    for row in rows:
        name_div = row.find("div", class_="valuta")
        code_div = row.find("div", class_="kod")
        rate_div = row.find("div", class_="kurs")

        if name_div and code_div and rate_div:
            name = name_div.text.strip()
            code = code_div.text.strip().upper()
            try:
                rate = float(rate_div.text.strip().replace(",", "."))
            except ValueError:
                continue

            # â— BAZA ÃœÃ‡ÃœN HÆR ZAMAN date_to_scrape
            cur.execute("""
                INSERT INTO exchange_rates (date, code, name, rate)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (date, code) DO NOTHING;
            """, (date_to_scrape.date(), code, name, rate))  # âœ… dÃ¼zgÃ¼n tarix

    conn.commit()
    cur.close()
    conn.close()
    print(f"âœ… {date_to_scrape.date()} mÉ™lumatlarÄ± uÄŸurla yazÄ±ldÄ±.")

# =========================
# KeÃ§miÅŸ datalarÄ± toplamaq
# =========================
def scrape_historical_data():
    start_date = datetime(1993, 11, 25)
    end_date = datetime.today()
    current_date = start_date

    print(f"ğŸ•“ {start_date.date()} â†’ {end_date.date()} arasÄ± tarixlÉ™r Ã¼Ã§Ã¼n mÉ™lumat yÄ±ÄŸÄ±lÄ±r...")

    while current_date <= end_date:
        try:
            scrape_currency(current_date)
        except Exception as e:
            print(f"âŒ XÉ™ta {current_date.date()}: {e}")
        time.sleep(1.5)  # saytÄ±n bloklanmamasÄ± Ã¼Ã§Ã¼n
        current_date += timedelta(days=1)

    print("âœ… KeÃ§miÅŸ mÉ™lumatlarÄ±n yÄ±ÄŸÄ±lmasÄ± tamamlandÄ±!")

# =========================
# GÃ¼ndÉ™lik yenilÉ™nmÉ™ funksiyasÄ±
# =========================
def scrape_today(**kwargs):
    date_to_scrape = datetime.strptime(kwargs['ds'], "%Y-%m-%d")
    scrape_currency(date_to_scrape)

# =========================
# Airflow DAG tÉ™rifi
# =========================
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2025, 10, 6),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'currency_scraper',
    default_args=default_args,
    schedule_interval='0 20 * * *',  # hÉ™r gÃ¼n saat 20:00-da
    catchup=False,
) as dag:

    # 1ï¸âƒ£ Bir dÉ™fÉ™lik keÃ§miÅŸ datalarÄ±n toplanmasÄ±
    task_scrape_history = PythonOperator(
        task_id='scrape_historical_data',
        python_callable=scrape_historical_data
    )

    # 2ï¸âƒ£ GÃ¼ndÉ™lik yeni mÉ™lumatlarÄ±n Ã§É™kilmÉ™si
    task_scrape_today = PythonOperator(
        task_id='scrape_today',
        python_callable=scrape_today,
        provide_context=True
    )

    task_scrape_history >> task_scrape_today
